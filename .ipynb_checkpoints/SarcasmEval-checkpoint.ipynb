{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bb7f4e3",
   "metadata": {},
   "source": [
    "<h1>The Tokenizers</h1>\n",
    "<hr>\n",
    "<h3>Group members: <span style=\"font-size:20px;\">Omar Dajani, Annwen Gammon, Mark Tamale</span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b6941c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/omardajani/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/omardajani/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/omardajani/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f75a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "train_df = pd.read_csv('data/train/train.En.csv')\n",
    "test_a_df = pd.read_csv('data/test/task_A_En_test.csv')\n",
    "test_b_df = pd.read_csv('data/test/task_B_En_test.csv')\n",
    "test_c_df = pd.read_csv('data/test/task_C_En_test.csv')\n",
    "\n",
    "train_df = train_df[['tweet', 'sarcastic']]\n",
    "test_b_df = test_b_df[['text', 'sarcasm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f6bc031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "      <td>thing got college caffeine addiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "      <td>love professor draw big question mark next ans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "      <td>remember hundred email company covid started g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "      <td>today poppop told forced go college okay sure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "      <td>volphancarol littlewhitty mysticalmanatee also...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>The population spike in Chicago in 9 months is...</td>\n",
       "      <td>0</td>\n",
       "      <td>population spike chicago month ridiculous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>You'd think in the second to last English clas...</td>\n",
       "      <td>0</td>\n",
       "      <td>youd think second last english class year prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465</th>\n",
       "      <td>I’m finally surfacing after a holiday to Scotl...</td>\n",
       "      <td>0</td>\n",
       "      <td>im finally surfacing holiday scotland difficul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>Couldn't be prouder today. Well done to every ...</td>\n",
       "      <td>0</td>\n",
       "      <td>couldnt prouder today well done every student ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>Overheard as my 13 year old games with a frien...</td>\n",
       "      <td>0</td>\n",
       "      <td>overheard year old game friend smell like tart...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3468 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  sarcastic  \\\n",
       "0     The only thing I got from college is a caffein...          1   \n",
       "1     I love it when professors draw a big question ...          1   \n",
       "2     Remember the hundred emails from companies whe...          1   \n",
       "3     Today my pop-pop told me I was not “forced” to...          1   \n",
       "4     @VolphanCarol @littlewhitty @mysticalmanatee I...          1   \n",
       "...                                                 ...        ...   \n",
       "3463  The population spike in Chicago in 9 months is...          0   \n",
       "3464  You'd think in the second to last English clas...          0   \n",
       "3465  I’m finally surfacing after a holiday to Scotl...          0   \n",
       "3466  Couldn't be prouder today. Well done to every ...          0   \n",
       "3467  Overheard as my 13 year old games with a frien...          0   \n",
       "\n",
       "                                              tokenized  \n",
       "0                  thing got college caffeine addiction  \n",
       "1     love professor draw big question mark next ans...  \n",
       "2     remember hundred email company covid started g...  \n",
       "3     today poppop told forced go college okay sure ...  \n",
       "4     volphancarol littlewhitty mysticalmanatee also...  \n",
       "...                                                 ...  \n",
       "3463          population spike chicago month ridiculous  \n",
       "3464  youd think second last english class year prof...  \n",
       "3465  im finally surfacing holiday scotland difficul...  \n",
       "3466  couldnt prouder today well done every student ...  \n",
       "3467  overheard year old game friend smell like tart...  \n",
       "\n",
       "[3468 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "removes any stop words e.g \"a\", \"an\", \"the\" etc...\n",
    "removes any numerical values / other values that are not part of the alphabet\n",
    "performs lemmatization on tokenized words\n",
    "\"\"\"\n",
    "def preprocess(text):\n",
    "    if isinstance(text, float):\n",
    "        text = str(text)\n",
    "    text = text.lower()\n",
    "    text = ''.join([word for word in text if not word.isdigit()])\n",
    "    text = ''.join([word for word in text if word.isalpha() or word.isspace()])\n",
    "    text = word_tokenize(text)\n",
    "    text = [word for word in text if word not in stopwords.words('english')]\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "train_df['tokenized'] = train_df['tweet'].apply(preprocess)\n",
    "train_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
