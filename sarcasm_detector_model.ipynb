{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itpOWhMn7oBW",
        "outputId": "6e2e7c25-c3a7-4a6f-d1b9-8721208767a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "fOPMwdxr7vlS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(5)"
      ],
      "metadata": {
        "id": "rSm5VP-2LxzE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KTnknhy8Mxh"
      },
      "source": [
        "<h1>Load dataset</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud1DOPiF7_D-",
        "outputId": "59fc9a85-c495-4478-f256-d67814f9770c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               tweet  sarcastic\n",
            "0  The only thing I got from college is a caffein...          1\n",
            "1  I love it when professors draw a big question ...          1\n",
            "2  Remember the hundred emails from companies whe...          1\n",
            "3  Today my pop-pop told me I was not ‚Äúforced‚Äù to...          1\n",
            "4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1 \n",
            "\n",
            "shape:  (3468, 2) \n",
            "\n",
            "class distribution:  0    0.75\n",
            "1    0.25\n",
            "Name: sarcastic, dtype: float64\n",
            "                                                text  sarcastic\n",
            "0  Size on the the Toulouse team, That pack is mo...          0\n",
            "1                                           Pinball!          0\n",
            "2  So the Scottish Government want people to get ...          1\n",
            "3  villainous pro tip : change the device name on...          0\n",
            "4                    I would date any of these men ü•∫          0\n"
          ]
        }
      ],
      "source": [
        "raw_df = pd.read_csv(\"data/train/train.En.csv\")\n",
        "df = raw_df.loc[:, ['tweet', 'sarcastic']]\n",
        "print(df.head(), \"\\n\")\n",
        "print(\"shape: \", df.shape, \"\\n\")\n",
        "print(\"class distribution: \", df['sarcastic'].value_counts(normalize = True))\n",
        "\n",
        "test_df = pd.read_csv(\"data/test/task_A_En_test.csv\")\n",
        "print(test_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksfzqA-G_O_E"
      },
      "source": [
        "<h1>Preprocess the data</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "oT3hYdLk_R-X"
      },
      "outputs": [],
      "source": [
        "df['tweet'] = df['tweet'].astype(str)\n",
        "test_df['text'] = test_df['text'].astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogxxGGb7mZDD"
      },
      "source": [
        "<h1>Splitting the training data into 90% training and 10% validation</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "gjye0_FTBD-Y"
      },
      "outputs": [],
      "source": [
        "train_text, valid_text, train_labels, valid_labels = train_test_split(df['tweet'], df['sarcastic'], \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.2, \n",
        "                                                                    stratify=df['sarcastic'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jPT-NJ19eAd"
      },
      "source": [
        "<h1>Importing BERT Model / BERT Tokenizer</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq78j2Ak8Y1t",
        "outputId": "b4800a9f-5718-4a21-be5e-b0745442b5f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "bert = AutoModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlJluKmE9sh6",
        "outputId": "506c883e-efd5-43f6-96f2-170a957c2574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 1996, 11190, 5598, 2058, 1996, 4231, 102, 0, 0, 0], [101, 1996, 4419, 5598, 2058, 1996, 4231, 1998, 5598, 2067, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ],
      "source": [
        "# testing out how sent ids work\n",
        "text = [\"the cow jumped over the moon\", \"the fox jumped over the moon and jumped back\"]\n",
        "\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)\n",
        "\n",
        "print(sent_id)\n",
        "\n",
        "# attention masks do not capture padding values, padding is added when one input is larger than the other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "h14Xd0PO-cVc",
        "outputId": "deae10ec-4cae-4246-89f2-400f8b2e7d14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "seq_len = [len(i.split()) for i in train_text]\n",
        "pd.Series(seq_len).hist(bins=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ify5ENQqAHQg"
      },
      "outputs": [],
      "source": [
        "max_seq_len = 25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PItabSonncQf"
      },
      "source": [
        "<h1>Tokenize data</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Esg3JR4sAOTW",
        "outputId": "bcd1681a-d9da-4eb1-f71f-a73bef3258ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    valid_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_df['text'].tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JETPIpqLnkd3"
      },
      "source": [
        "<h1>Convert integer sequences to tensors</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "1o5WGDD6IIxO"
      },
      "outputs": [],
      "source": [
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(valid_labels.tolist())\n",
        "\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_df['sarcastic'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "OsMb1i-qIyD6"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y) # wrap tensors\n",
        "train_sampler = RandomSampler(train_data) # used for sampling in training\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size) # dataloader\n",
        "\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "val_sampler = SequentialSampler(val_data) # used for sampling in validation\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "il9bVt3_JG7k"
      },
      "outputs": [],
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "wXG_jBOXJMKK"
      },
      "outputs": [],
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "    def __init__(self, bert):\n",
        "        super(BERT_Arch, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(768, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 2)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, sent_id, mask):\n",
        "        _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
        "        x = self.fc1(cls_hs)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cehVAIruJnj2",
        "outputId": "8e57c25f-aadf-4595-ea48-589cb5cb3516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "The current device is Tesla T4\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          \n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print(f'The current device is {torch.cuda.get_device_name(0)}')\n",
        "else:\n",
        "    print('CUDA is not available. Using CPU...')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn6j0UQBJsHp",
        "outputId": "8429528d-eb9d-456e-e02b-45c94b3320a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.66682692 1.99855908]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "class_wts = compute_class_weight(class_weight=\"balanced\", classes=np.unique(train_labels), y=train_labels)\n",
        "\n",
        "print(class_wts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "RkkOIaXgLP50"
      },
      "outputs": [],
      "source": [
        "# class weights to sensors\n",
        "weights = torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "cross_entropy = nn.NLLLoss(weight=weights) # loss function\n",
        "\n",
        "# number of training epochs\n",
        "epochs = 20\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "kD5nRIzjLWbZ"
      },
      "outputs": [],
      "source": [
        "from torch.optim import SGD\n",
        "\n",
        "optimizer = SGD(model.parameters(), lr=0.009, momentum=0.9) # optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBx3GzfSqtB3"
      },
      "source": [
        "<h1>Fine-Tuning BERT</h1>\n",
        "<p>In this cell we are saving the model predictions while iterating over batches. For each batch, we clear the previously calculated gradients and get the model's predictions for the current batch. We then calculate the loss between the actual and predicted values which is added to the total loss. We then backward pass to calculate the gradients and clip the gradients to 1.0 which helps to prevent exploding gradients. Finally, we update the parameters and append the predictions to a list of stored predictions.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "23yYYXyRLer1"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "  model.train()\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  total_preds=[]\n",
        "  \n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    batch = [r.to(device) for r in batch]\n",
        "    sent_id, mask, labels = batch\n",
        "    model.zero_grad()        \n",
        "    preds = model(sent_id, mask)\n",
        "    loss = cross_entropy(preds, labels)\n",
        "    total_loss = total_loss + loss.item()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GTyS2YcrZqC"
      },
      "source": [
        "<h1>Evaluating the model</h1>\n",
        "<p>In this cell we are computing the validation loss between the actual and predicted loss.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "m9sEOlnpLrGL"
      },
      "outputs": [],
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  print(\"\\nEvaluating...\")\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  total_preds = []\n",
        "\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "      preds = model(sent_id, mask)\n",
        "      loss = cross_entropy(preds,labels)\n",
        "      total_loss = total_loss + loss.item()\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOxQVxCfszo9"
      },
      "source": [
        "<h1>Model training</h1>\n",
        "Here we are training, evaluating and saving the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH8qYQ4lLuRy",
        "outputId": "9088790c-f005-4165-f94c-e2be81e371c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 20\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.695\n",
            "Validation Loss: 0.692\n",
            "\n",
            " Epoch 2 / 20\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.693\n",
            "Validation Loss: 0.692\n",
            "\n",
            " Epoch 3 / 20\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.693\n",
            "Validation Loss: 0.692\n",
            "\n",
            " Epoch 4 / 20\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.693\n",
            "Validation Loss: 0.696\n",
            "\n",
            " Epoch 5 / 20\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.693\n",
            "Validation Loss: 0.693\n",
            "\n",
            " Epoch 6 / 20\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.694\n",
            "Validation Loss: 0.692\n",
            "\n",
            " Epoch 7 / 20\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.694\n",
            "Validation Loss: 0.692\n",
            "\n",
            " Epoch 8 / 20\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.693\n",
            "Validation Loss: 0.692\n",
            "\n",
            " Epoch 9 / 20\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.693\n",
            "Validation Loss: 0.694\n",
            "\n",
            " Epoch 10 / 20\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.694\n",
            "Validation Loss: 0.692\n",
            "\n",
            " Epoch 11 / 20\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.693\n",
            "Validation Loss: 0.692\n",
            "\n",
            " Epoch 12 / 20\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.692\n",
            "Validation Loss: 0.692\n",
            "\n",
            " Epoch 13 / 20\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.694\n",
            "Validation Loss: 0.692\n",
            "\n",
            " Epoch 14 / 20\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.693\n",
            "Validation Loss: 0.693\n",
            "\n",
            " Epoch 15 / 20\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.694\n",
            "Validation Loss: 0.692\n",
            "\n",
            " Epoch 16 / 20\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.692\n",
            "Validation Loss: 0.692\n",
            "\n",
            " Epoch 17 / 20\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.692\n",
            "Validation Loss: 0.692\n",
            "\n",
            " Epoch 18 / 20\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.692\n",
            "Validation Loss: 0.693\n",
            "\n",
            " Epoch 19 / 20\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.691\n",
            "Validation Loss: 0.695\n",
            "\n",
            " Epoch 20 / 20\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.690\n",
            "Validation Loss: 0.692\n"
          ]
        }
      ],
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "KMD9AmLEQRad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c1d191e-c8f7-4438-c27b-ebc2b1a7a22c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ZR6NUqHlQUnq"
      },
      "outputs": [],
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Ee-2ITm2QYc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7441b1f-fe02-457f-b7c9-aa263bc87ca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.69      0.76      1200\n",
            "           1       0.09      0.17      0.12       200\n",
            "\n",
            "    accuracy                           0.62      1400\n",
            "   macro avg       0.46      0.43      0.44      1400\n",
            "weighted avg       0.73      0.62      0.66      1400\n",
            "\n",
            "0.43560445379086676 0.6642422413878319\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))\n",
        "macro_f1 = f1_score(test_y, preds, average='macro')\n",
        "weighted_f1 = f1_score(test_y, preds, average='weighted')\n",
        "print(macro_f1, weighted_f1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}